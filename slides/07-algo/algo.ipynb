{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Algorithms\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.4\n",
      "Commit 8561cc3d68d (2025-03-10 11:36 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin24.0.0)\n",
      "  CPU: 12 × Apple M2 Max\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, apple-m2)\n",
      "Threads: 8 default, 0 interactive, 4 GC (on 8 virtual cores)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n",
      "  JULIA_EDITOR = code\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Documents/github.com/ucla-biostat-257/2025spring/slides/07-algo/Project.toml`\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.6.0\n",
      "  \u001b[90m[37e2e46d] \u001b[39mLinearAlgebra v1.11.0\n",
      "  \u001b[90m[9a3f8284] \u001b[39mRandom v1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/github.com/ucla-biostat-257/2025spring/slides/07-algo`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition\n",
    "\n",
    "* Algorithm is loosely defined as a set of instructions for doing something. Input $\\to$ Output.\n",
    "\n",
    "* [Knuth](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming): (1) finiteness, (2) definiteness, (3) input, (4) output, (5) effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure of efficiency\n",
    "\n",
    "* A basic unit for measuring algorithmic efficiency is **flop**.  \n",
    "\n",
    "> A flop (**floating point operation**) consists of a floating point addition, subtraction, multiplication, division, or comparison, and the usually accompanying fetch and store.  \n",
    "\n",
    "* Some books count multiplication followed by an addition (fused multiply-add, FMA) as one flop. This results a factor of up to 2 difference in flop counts.\n",
    "\n",
    "* How to measure efficiency of an algorithm? Big O notation. If $n$ is the size of a problem, an algorithm has order $O(f(n))$, where the leading term in the number of flops is $c \\cdot f(n)$. For example,\n",
    "    - matrix-vector multiplication `A * b`, where `A` is $m \\times n$ and `b` is $n \\times 1$, takes $2mn$ or $O(mn)$ flops  \n",
    "    - matrix-matrix multiplication `A * B`, where `A` is $m \\times n$ and `B` is $n \\times p$, takes $2mnp$ or $O(mnp)$ flops\n",
    "\n",
    "* A hierarchy of computational complexity:  \n",
    "    Let $n$ be the problem size.\n",
    "    - Exponential order: $O(b^n)$ (NP-hard=\"horrible\")    \n",
    "    - Polynomial order: $O(n^q)$ (doable)  \n",
    "    - $O(n \\log n )$ (fast)  \n",
    "    - Linear order $O(n)$ (fast)  \n",
    "    - Log order $O(\\log n)$ (super fast)  \n",
    "    \n",
    "* Classification of data sets by [Huber](http://link.springer.com/chapter/10.1007%2F978-3-642-52463-9_1).\n",
    "\n",
    "| Data Size | Bytes     | Storage Mode          |\n",
    "|-----------|-----------|-----------------------|\n",
    "| Tiny      | $10^2$    | Piece of paper        |\n",
    "| Small     | $10^4$    | A few pieces of paper |\n",
    "| Medium    | $10^6$ (megatbytes)    | A floppy disk         |\n",
    "| Large     | $10^8$    | Hard disk             |\n",
    "| Huge      | $10^9$ (gigabytes)   | Hard disk(s)          |\n",
    "| Massive   | $10^{12}$ (terabytes) | RAID storage          |\n",
    "\n",
    "* Difference of $O(n^2)$ and $O(n\\log n)$ on massive data. Suppose we have a teraflop supercomputer capable of doing $10^{12}$ flops per second. For a problem of size $n=10^{12}$, $O(n \\log n)$ algorithm takes about \n",
    "$$10^{12} \\log (10^{12}) / 10^{12} \\approx 27 \\text{ seconds}.$$ \n",
    "$O(n^2)$ algorithm takes about $10^{12}$ seconds, which is approximately 31710 years!\n",
    "\n",
    "* QuickSort and FFT (invented by statistician John Tukey!) are celebrated algorithms that turn $O(n^2)$ operations into $O(n \\log n)$. Another example is the Strassen's method, which turns $O(n^3)$ matrix multiplication into $O(n^{\\log_2 7})$.\n",
    "\n",
    "* One goal of this course is to get familiar with the flop counts for some common numerical tasks in statistics.   \n",
    "\n",
    "> **The form of a mathematical expression and the way the expression should be evaluated in actual practice may be quite different.**\n",
    "\n",
    "* For example, compare flops of the two mathematically equivalent expressions: `(A * B) * x` and `A * (B * x)` where `A` and `B` are matrices and `x` is a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 665 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m6.643 ms\u001b[22m\u001b[39m … \u001b[35m 11.585 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 9.36%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m7.271 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m7.502 ms\u001b[22m\u001b[39m ± \u001b[32m872.489 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.55% ± 4.02%\n",
       "\n",
       "  \u001b[39m▂\u001b[39m█\u001b[39m▅\u001b[39m▄\u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▃\u001b[34m▃\u001b[39m\u001b[39m▂\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▄\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m▇\u001b[32m▆\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▁\u001b[39m▃\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
       "  6.64 ms\u001b[90m         Histogram: frequency by time\u001b[39m        10.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m7.64 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Random\n",
    "\n",
    "Random.seed!(257) # seed\n",
    "n = 1000\n",
    "A = randn(n, n)\n",
    "B = randn(n, n)\n",
    "x = randn(n)\n",
    "\n",
    "# complexity is n^3 + n^2 = O(n^3)\n",
    "bm1 = @benchmark ($A * $B) * $x\n",
    "bm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation per sample.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m171.291 μs\u001b[22m\u001b[39m … \u001b[35m  7.665 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m258.500 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m301.484 μs\u001b[22m\u001b[39m ± \u001b[32m240.708 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.24% ± 1.50%\n",
       "\n",
       "  \u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[34m▇\u001b[39m\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[32m▅\u001b[39m\u001b[39m▇\u001b[39m▅\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▃\u001b[39m▄\u001b[39m▅\u001b[39m▃\u001b[39m▆\u001b[39m \u001b[39m█\n",
       "  171 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m        990 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m15.88 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# complexity is n^2 + n^2 = O(n^2)\n",
    "bm2 = @benchmark $A * ($B * $x)\n",
    "bm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.12717601547389"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Speed up\n",
    "median(bm1.times) / median(bm2.times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodeInfo(\n",
       "\u001b[90m1 ─\u001b[39m %1 = LinearAlgebra.:*\n",
       "\u001b[90m│  \u001b[39m %2 = B * x\n",
       "\u001b[90m│  \u001b[39m %3 = (%1)(A, %2)\n",
       "\u001b[90m└──\u001b[39m      return %3\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fortunately, Julia parsed the following code in the more efficient way\n",
    "# No luck with some other languages\n",
    "@code_lowered A * B * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of computer systems\n",
    "\n",
    "* **FLOPS** (floating point operations per second) is a measure of computer performance. \n",
    "\n",
    "* For example, this laptop has the [Apple M2](https://en.wikipedia.org/wiki/Apple_M2) Max CPU with 8 performance cores and 4 efficiency cores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.4\n",
      "Commit 8561cc3d68d (2025-03-10 11:36 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin24.0.0)\n",
      "  CPU: 12 × Apple M2 Max\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, apple-m2)\n",
      "Threads: 8 default, 0 interactive, 4 GC (on 8 virtual cores)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n",
      "  JULIA_EDITOR = code\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Intel Skylake CPUs can do 16 DP flops per cylce and 32 SP flops per cycle. Then the **theoretical throughput** of my laptop is\n",
    "$$ 4 \\times 2.9 \\times 10^9 \\times 16 = 185.6 \\text{ GFLOPS DP} $$\n",
    "in double precision and\n",
    "$$ 4 \\times 2.9 \\times 10^9 \\times 32 = 371.2 \\text{ GFLOPS SP} $$\n",
    "in single precision.  -->\n",
    "\n",
    "* In Julia, `LinearAlgebra.peakflops` computes the peak flop rate of the computer by running **double precision** matrix-matrix multiplication `BLAS.gemm!`. About 350 GFLOPS DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.61375509490603e11"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "\n",
    "# Double-precison throughput\n",
    "LinearAlgebra.peakflops(2^14) # matrix size 2^14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We roughtly estimate the **single precision**  thoughput by (# flops / runtime). About 700 GFLOPS SP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1 sample with 1 evaluation per sample.\n",
       " Single result which took \u001b[34m11.863 s\u001b[39m (0.00% GC) to evaluate,\n",
       " with a memory estimate of \u001b[33m0 bytes\u001b[39m, over \u001b[33m0\u001b[39m allocations."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Random\n",
    "\n",
    "# Generate matrix data\n",
    "Random.seed!(257)\n",
    "n = 2^14\n",
    "A = randn(Float32, n, n)\n",
    "B = randn(Float32, n, n)\n",
    "C = Matrix{Float32}(undef, n, n)\n",
    "\n",
    "# Single-precision throughput\n",
    "bm = @benchmark mul!(C, A, B)\n",
    "bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.414805131805767e11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate single precision throughput by # flops / runtime\n",
    "(2n^3) / (minimum(bm.times) / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a later lecture, we'll see graphical processing units (GPUs) offer a much larger thoughput in single precision."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "67px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
