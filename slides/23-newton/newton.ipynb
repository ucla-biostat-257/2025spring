{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: Newton's Method and Fisher Scoring (KL Chapter 14)\n",
    "subtitle: Biostat/Biomath M257\n",
    "author: Dr. Hua Zhou @ UCLA\n",
    "date: today\n",
    "format:\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    embed-resources: true\n",
    "    number-sections: true\n",
    "    toc: true\n",
    "    toc-depth: 4\n",
    "    toc-location: left\n",
    "    code-fold: false\n",
    "    link-external-icon: true\n",
    "    link-external-newwindow: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System information (for reproducibility):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.11.5\n",
      "Commit 760b2e5b739 (2025-04-14 06:53 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (arm64-apple-darwin24.0.0)\n",
      "  CPU: 12 Ã— Apple M2 Max\n",
      "  WORD_SIZE: 64\n",
      "  LLVM: libLLVM-16.0.6 (ORCJIT, apple-m2)\n",
      "Threads: 8 default, 0 interactive, 4 GC (on 8 virtual cores)\n",
      "Environment:\n",
      "  JULIA_NUM_THREADS = 8\n",
      "  JULIA_EDITOR = code\n",
      "  DYLD_FALLBACK_LIBRARY_PATH = /Users/huazhou/.julia/artifacts/c1600fa286afe4bf3616780a19b65285c63968ca/lib:/Users/huazhou/.julia/artifacts/b820a0a437e8501d06a17439abd84feaa5b6cca3/lib:/Users/huazhou/.julia/artifacts/5b90ad21b4b1af3a9446241fb5afe3e3b3eda941/lib:/Users/huazhou/.julia/juliaup/julia-1.11.5+0.aarch64.apple.darwin14/lib/julia:/Users/huazhou/.julia/artifacts/c99c0e2b61a41b4b2294b30e9f7f26e50c2e38eb/lib:/Users/huazhou/.julia/artifacts/9410bad2635eda2239b4a72ba4316c4aa8f5b76e/lib:/Users/huazhou/.julia/artifacts/3b568c51fbf75bfe59ac69d26b176034fdd63ebb/lib:/Users/huazhou/.julia/artifacts/21209a2ac399ce693d73daf1aa8d670fbc84d70f/lib:/Users/huazhou/.julia/artifacts/c59059ef20910985e15a497e3f3f9f5a01df2645/lib:/Users/huazhou/.julia/artifacts/c4b9929ae9f0b6e0230d975f1e65ec59507e3e80/lib:/Users/huazhou/.julia/artifacts/365365262519d2f165f6ca9bdc0f104718889a88/lib:/Users/huazhou/.julia/artifacts/becfd6f89f1a272ace2375b067f1153515ca70b3/lib:/Users/huazhou/.julia/artifacts/f00ec04851ced5895bd99297d49916ba59ca783d/lib:/Users/huazhou/.julia/artifacts/6ebc40d37ee48f23c8a0edb94c2f1a8622edba3a/lib:/Users/huazhou/.julia/artifacts/1994697285dfe8747ff7ec6927666edc88750202/lib:/Users/huazhou/.julia/artifacts/c5d5b7c7e77b04af2eabde40ebbf379932d8bfd7/lib:/Users/huazhou/.julia/artifacts/81e1d2f3a1459f121eaae539b9549e9e740a6c62/lib:/Users/huazhou/.julia/artifacts/a3e73ecf5d803bb3792a23f0382a2b5573383647/lib:/Users/huazhou/.julia/artifacts/67723a86975c82b43f01cda306999b382d3435f0/lib:/Users/huazhou/.julia/artifacts/115f3a18328d7b88e31c9e3f095aeb12eb381710/lib:/Users/huazhou/.julia/artifacts/ca2831bf6edc5088aec5b329ea98364951d6cad0/lib:/Users/huazhou/.julia/artifacts/477447566a69a531a7a3f8e0130cbfe460b37eec/lib:/Users/huazhou/.julia/artifacts/b58891667c46c467bd51be0e963c1ef1f0314934/lib:/Users/huazhou/.julia/artifacts/0db9c3f6cf936a0da49e2ba954ba3e10bed6ad72/lib:/Users/huazhou/.julia/artifacts/1a7e22e66b523d9cb884cf85c3ec065b5fb3e5c3/lib:/Users/huazhou/.julia/artifacts/84fa3b322bb3bbb0d733f9f1498ca286422dfab3/lib:/Users/huazhou/.julia/artifacts/83ff444c229f9dd64a13999123a4eb14e632d67a/lib:/Users/huazhou/.julia/artifacts/6095fcd268ea712c0f786f5ff1a45bf0eb7b005e/lib:/Users/huazhou/.julia/artifacts/7ead0a440ba045155db235bff6602a984f08a651/lib:/Users/huazhou/.julia/artifacts/9d8a957aa3387b17b8639251016c87710db1a175/lib:/Users/huazhou/.julia/artifacts/63d48e4aab8721470f588bdeb1e2b462ee3b6a68/lib:/Users/huazhou/.julia/artifacts/4ed6227ff66b34dcd65f011ad8b91bdf545ac4d8/lib:/Users/huazhou/.julia/artifacts/8da603395acfbdbef8c5de3b7223aeb9276ecbdb/lib:/Users/huazhou/.julia/artifacts/932f282690a789f3744abcd83fb9f68ba7ed4c19/lib:/Users/huazhou/.julia/artifacts/4b3b2d79556cc3aef6e3d8a234649cc85b91bb87/lib:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtConcurrent.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtCore.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtDBus.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtGui.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtNetwork.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtOpenGL.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtPrintSupport.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtSql.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtTest.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtWidgets.framework/Versions/A:/Users/huazhou/.julia/artifacts/7f2122f84c49e5b75c5b4cbf46bbdeb3b0ffc5da/lib/QtXml.framework/Versions/A:/Users/huazhou/.julia/artifacts/6ac5d5e20ad53d5594a298f35287b91138ac419d/lib:/Users/huazhou/.julia/juliaup/julia-1.11.5+0.aarch64.apple.darwin14/bin/../lib/julia:/Users/huazhou/.julia/juliaup/julia-1.11.5+0.aarch64.apple.darwin14/bin/../lib:\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/github.com/ucla-biostat-257/2025spring/slides/23-newton`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Documents/github.com/ucla-biostat-257/2025spring/slides/23-newton/Project.toml`\n",
      "  \u001b[90m[f6369f11] \u001b[39mForwardDiff v1.0.1\n",
      "  \u001b[90m[b964fa9f] \u001b[39mLaTeXStrings v1.4.0\n",
      "  \u001b[90m[91a5bcdd] \u001b[39mPlots v1.40.13\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "\n",
    "Consider maximizing log-likelihood function $L(\\mathbf{\\theta})$, $\\theta \\in \\Theta \\subset \\mathbb{R}^p$.\n",
    "\n",
    "* **Gradient** (or **score**) of $L$:\n",
    "    $$\n",
    "    \\nabla L(\\theta) = \\begin{pmatrix}\n",
    "    \\frac{\\partial L(\\theta)}{\\partial \\theta_1} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\frac{\\partial L(\\theta)}{\\partial \\theta_p}\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    " \n",
    "* **Hessian** of $L$:  \n",
    "    $$\n",
    "    \\nabla^2 L(\\theta) = \\begin{pmatrix}\n",
    "    \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_1 \\partial \\theta_1} & \\dots & \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_1 \\partial \\theta_p} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_p \\partial \\theta_1} & \\dots & \\frac{\\partial^2 L(\\theta)}{\\partial \\theta_p \\partial \\theta_p}\n",
    "    \\end{pmatrix}\n",
    "    $$\n",
    "    \n",
    "* **Observed information matrix** (negative Hessian):  \n",
    "\n",
    "$$\n",
    "    - \\nabla^2 L(\\theta)\n",
    "$$\n",
    "    \n",
    "* **Expected (Fisher) information matrix**: \n",
    "$$\n",
    "    \\mathbf{E}[- \\nabla^2 L(\\theta)].\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method\n",
    "\n",
    "* Newton's method was originally developed for finding roots of nonlinear equations\n",
    "$f(\\mathbf{x}) = \\mathbf{0}$ (KL 5.4).\n",
    "\n",
    "* Newton's method, aka **Newton-Raphson method**, is considered the gold standard for its fast (quadratic) convergence\n",
    "$$\n",
    "\t\\frac{\\|\\mathbf{\\theta}^{(t+1)} - \\mathbf{\\theta}^*\\|}{\\|\\mathbf{\\theta}^{(t)} - \\mathbf{\\theta}^*\\|^2} \\to \\text{constant}.\n",
    "$$\n",
    "\n",
    "* Idea: iterative quadratic approximation. \n",
    "\n",
    "* Taylor expansion around the current iterate $\\mathbf{\\theta}^{(t)}$\n",
    "$$\n",
    "\tL(\\mathbf{\\theta}) \\approx L(\\mathbf{\\theta}^{(t)}) + \\nabla L(\\mathbf{\\theta}^{(t)})^T (\\mathbf{\\theta} - \\mathbf{\\theta}^{(t)}) + \\frac 12 (\\mathbf{\\theta} - \\mathbf{\\theta}^{(t)})^T [\\nabla^2L(\\mathbf{\\theta}^{(t)})] (\\mathbf{\\theta} - \\mathbf{\\theta}^{(t)})\n",
    "$$\n",
    "and then maximize the quadratic approximation.\n",
    "\n",
    "* To maximize the quadratic function, we equate its gradient to zero\n",
    "$$\n",
    "\t\\nabla L(\\theta^{(t)}) + [\\nabla^2L(\\theta^{(t)})] (\\theta - \\theta^{(t)}) = \\mathbf{0}_p,\n",
    "$$\n",
    "which suggests the next iterate\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\theta^{(t+1)} &=& \\theta^{(t)} - [\\nabla^2L(\\theta^{(t)})]^{-1} \\nabla L(\\theta^{(t)}) \\\\\n",
    "\t&=& \\theta^{(t)} + [-\\nabla^2L(\\theta^{(t)})]^{-1} \\nabla L(\\theta^{(t)}).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "We call this **naive Newton's method**.\n",
    "\n",
    "* **Stability issue**: naive Newton's iterate is **not** guaranteed to be an ascent algorithm. It's equally happy to head uphill or downhill. Following example shows that the Newton iterate converges to a local maximum, converges to a local minimum, or diverges depending on starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code-eval": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSaved animation to /Users/huazhou/Documents/github.com/ucla-biostat-257/2025spring/slides/23-newton/tmp.gif\n"
     ]
    }
   ],
   "source": [
    "using Plots; gr()\n",
    "using LaTeXStrings, ForwardDiff\n",
    "\n",
    "f(x) = sin(x)\n",
    "df  = x -> ForwardDiff.derivative(f, x) # gradient\n",
    "d2f = x -> ForwardDiff.derivative(df, x) # hessian\n",
    "x = 2.0 # start point: 2.0 (local maximum), 2.75 (diverge), 4.0 (local minimum)\n",
    "titletext = \"Starting point: $x\"\n",
    "anim = @animate for iter in 0:10\n",
    "    iter > 0 && (global x = x - d2f(x) \\ df(x))\n",
    "    p = Plots.plot(f, 0, 2Ï€, xlim=(0, 2Ï€), ylim=(-1.1, 1.1), legend=nothing, title=titletext)\n",
    "    Plots.plot!(p, [x], [f(x)], shape=:circle)\n",
    "    Plots.annotate!(p, x, f(x), text(latexstring(\"x^{($iter)}\"), :right))\n",
    "end\n",
    "gif(anim, \"./tmp.gif\", fps = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./newton_demo_1.gif)\n",
    "![](./newton_demo_2.gif)\n",
    "![](./newton_demo_3.gif)\n",
    "\n",
    "* Remedies for the instability issue:\n",
    "    1. approximate $-\\nabla^2L(\\theta^{(t)})$ by a positive definite $\\mathbf{A}$ (if it's not), **and** \n",
    "    2. line search (backtracking).   \n",
    "\n",
    "* Why insist on a _positive definite_ approximation of Hessian? By first-order Taylor expansion,\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    & & L(\\theta^{(t)} + s \\Delta \\theta^{(t)}) - L(\\theta^{(t)}) \\\\\n",
    "    &=& L(\\theta^{(t)}) + s \\cdot \\nabla L(\\theta^{(t)})^T \\Delta \\theta^{(t)} + o(s) - L(\\theta^{(t)}) \\\\\n",
    "    &=& s \\cdot \\nabla L(\\theta^{(t)})^T \\Delta \\theta^{(t)} + o(s) \\\\\n",
    "    &=& s \\cdot \\nabla L(\\theta^{(t)})^T [\\mathbf{A}^{(t)}]^{-1} \\nabla L(\\theta^{(t)}) + o(s).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "For $s$ sufficiently small, right hand side is strictly positive when $\\mathbf{A}^{(t)}$ is positive definite. The quantity $\\{\\nabla L(\\theta^{(t)})^T [\\mathbf{A}^{(t)}]^{-1} \\nabla L(\\theta^{(t)})\\}^{1/2}$ is termed the **Newton decrement**.\n",
    "\n",
    "* In summary, a **practical Newton-type algorithm** iterates according to\n",
    "$$\n",
    "\t\\boxed{ \\theta^{(t+1)} = \\theta^{(t)} + s [\\mathbf{A}^{(t)}]^{-1} \\nabla L(\\theta^{(t)}) \n",
    "\t= \\theta^{(t)} + s \\Delta \\theta^{(t)} }\n",
    "$$\n",
    "where $\\mathbf{A}^{(t)}$ is a pd approximation of $-\\nabla^2L(\\theta^{(t)})$ and $s$ is a step length.\n",
    "\n",
    "* For strictly concave $L$, $-\\nabla^2L(\\theta^{(t)})$ is always positive definite. Line search is still needed to guarantee convergence.\n",
    "\n",
    "* Line search strategy: step-halving ($s=1,1/2,\\ldots$), golden section search, cubic interpolation, Amijo rule, ... Note the **Newton direction**  \n",
    "$$\n",
    "\\Delta \\theta^{(t)} = [\\mathbf{A}^{(t)}]^{-1} \\nabla L(\\theta^{(t)})\n",
    "$$\n",
    "only needs to be calculated once. Cost of line search mainly lies in objective function evaluation.\n",
    "\n",
    "* How to approximate $-\\nabla^2L(\\theta)$? More of an art than science. Often requires problem specific analysis. \n",
    "\n",
    "* Taking $\\mathbf{A} = \\mathbf{I}$ leads to the method of **steepest ascent**, aka  **gradient ascent**.\n",
    "\n",
    "<img src=\"http://trond.hjorteland.com/thesis/img208.gif\" width=\"400\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fisher's scoring method\n",
    "\n",
    "* **Fisher's scoring method**: replace $- \\nabla^2L(\\theta)$ by the expected Fisher information matrix\n",
    "$$\n",
    "\t\\mathbf{FIM}(\\theta) = \\mathbf{E}[-\\nabla^2L(\\theta)] = \\mathbf{E}[\\nabla L(\\theta) \\nabla L(\\theta)^T] \\succeq \\mathbf{0}_{p \\times p},\n",
    "$$\n",
    "which is psd under exchangeability of expectation and differentiation.\n",
    "\n",
    "    Therefore the Fisher's scoring algorithm iterates according to\n",
    "$$\n",
    "\t\\boxed{ \\theta^{(t+1)} = \\theta^{(t)} + s [\\mathbf{FIM}(\\theta^{(t)})]^{-1} \\nabla L(\\theta^{(t)})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalized linear model (GLM) (KL 14.7)\n",
    "\n",
    "### Logistic regression\n",
    "\n",
    "Let's consider a concrete example: logistic regression.\n",
    "\n",
    "* The goal is to predict whether a credit card transaction is fraud ($y_i=1$) or not ($y_i=0$). Predictors ($\\mathbf{x}_i$) include: time of transaction, last location, merchant, ...\n",
    "\n",
    "* $y_i \\in \\{0,1\\}$, $\\mathbf{x}_i \\in \\mathbb{R}^{p}$. Model $y_i \\sim $Bernoulli$(p_i)$.\n",
    "\n",
    "* Logistic regression. Density\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\tf(y_i|p_i) &=& p_i^{y_i} (1-p_i)^{1-y_i} \\\\\n",
    "\t&=& e^{y_i \\ln p_i + (1-y_i) \\ln (1-p_i)} \\\\\n",
    "\t&=& e^{y_i \\ln \\frac{p_i}{1-p_i} + \\ln (1-p_i)},\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\mathbf{E} (y_i) = p_i &=& \\frac{e^{\\eta_i}}{1+ e^{\\eta_i}} \\quad \\text{(mean function, inverse link function)} \\\\\n",
    "\t\\eta_i = \\mathbf{x}_i^T \\beta &=& \\ln \\left( \\frac{p_i}{1-p_i} \\right) \\quad \\text{(logit link function)}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "* Given data $(y_i,\\mathbf{x}_i)$, $i=1,\\ldots,n$,\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\tL_n(\\beta) &=& \\sum_{i=1}^n \\left[ y_i \\ln p_i + (1-y_i) \\ln (1-p_i) \\right] \\\\\n",
    "\t&=& \\sum_{i=1}^n \\left[ y_i \\mathbf{x}_i^T \\beta - \\ln (1 + e^{\\mathbf{x}_i^T \\beta}) \\right] \\\\\n",
    "\t\\nabla L_n(\\beta) &=& \\sum_{i=1}^n \\left( y_i \\mathbf{x}_i - \\frac{e^{\\mathbf{x}_i^T \\beta}}{1+e^{\\mathbf{x}_i^T \\beta}} \\mathbf{x}_i \\right) \\\\\n",
    "\t&=& \\sum_{i=1}^n (y_i - p_i) \\mathbf{x}_i = \\mathbf{X}^T (\\mathbf{y} - \\mathbf{p})\t\\\\\n",
    "\t- \\nabla^2L_n(\\beta) &=& \\sum_{i=1}^n p_i(1-p_i) \\mathbf{x}_i \\mathbf{x}_i^T = \\mathbf{X}^T \\mathbf{W} \\mathbf{X}, \\quad\n",
    "\t\\text{where } \\mathbf{W} &=& \\text{diag}(w_1,\\ldots,w_n), w_i = p_i (1-p_i) \\\\\n",
    "\t\\mathbf{FIM}_n(\\beta) &=& \\mathbf{E} [- \\nabla^2L_n(\\beta)] = - \\nabla^2L_n(\\beta).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "* Newton's method == Fisher's scoring iteration: \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\beta^{(t+1)} &=& \\beta^{(t)} + s[-\\nabla^2 L(\\beta^{(t)})]^{-1} \\nabla L(\\beta^{(t)})\t\\\\\n",
    "\t&=& \\beta^{(t)} + s(\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T (\\mathbf{y} - \\mathbf{p}^{(t)}) \\\\\n",
    "\t&=& (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} \\left[ \\mathbf{X} \\beta^{(t)} + s(\\mathbf{W}^{(t)})^{-1} (\\mathbf{y} - \\mathbf{p}^{(t)}) \\right] \\\\\n",
    "\t&=& (\\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{W}^{(t)} \\mathbf{z}^{(t)},\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "where \n",
    "$$\n",
    "\t\\mathbf{z}^{(t)} = \\mathbf{X} \\beta^{(t)} + s(\\mathbf{W}^{(t)})^{-1} (\\mathbf{y} - \\mathbf{p}^{(t)})\n",
    "$$ \n",
    "are the working responses. A Newton's iteration is equivalent to solving a weighed least squares problem $\\sum_{i=1}^n w_i (z_i - \\mathbf{x}_i^T \\beta)^2$. Thus the name **IRWLS (iteratively re-weighted least squares)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM \n",
    "\n",
    "Let's consider the more general class of generalized linear models (GLM).\n",
    "\n",
    "\n",
    "| Family           | Canonical Link                          | Variance Function |\n",
    "|------------------|-------------------------------|-------------------|\n",
    "| Normal           | $\\eta=\\mu$                    | 1                 |\n",
    "| Poisson          | $\\eta=\\log \\mu$               | $\\mu$             |\n",
    "| Binomial         | $\\eta=\\log \\left( \\frac{\\mu}{1 - \\mu} \\right)$ | $\\mu (1 - \\mu)$   |\n",
    "| Gamma            | $\\eta = \\mu^{-1}$             | $\\mu^2$           |\n",
    "| Inverse Gaussian | $\\eta = \\mu^{-2}$             | $\\mu^3$           |\n",
    "\n",
    "* $Y$ belongs to an exponential family with density\n",
    "$$\n",
    "\tp(y|\\theta,\\phi) = \\exp \\left\\{ \\frac{y\\theta - b(\\theta)}{a(\\phi)} + c(y,\\phi) \\right\\}.\n",
    "$$\n",
    "    * $\\theta$: natural parameter.  \n",
    "    * $\\phi>0$: dispersion parameter.  \n",
    "GLM relates the mean $\\mu = \\mathbf{E}(Y|\\mathbf{x})$ via a strictly increasing link function\n",
    "$$\n",
    "\tg(\\mu) = \\eta = \\mathbf{x}^T \\beta, \\quad \\mu = g^{-1}(\\eta)\n",
    "$$\n",
    "\n",
    "* Score, Hessian, information\n",
    "\n",
    "\\begin{eqnarray*}\n",
    " \t\\nabla L_n(\\beta) &=& \\sum_{i=1}^n \\frac{(y_i-\\mu_i) \\mu_i'(\\eta_i)}{\\sigma_i^2} \\mathbf{x}_i \\\\\n",
    "    \\,- \\nabla^2 L_n(\\boldsymbol{\\beta}) &=& \\sum_{i=1}^n \\frac{[\\mu_i'(\\eta_i)]^2}{\\sigma_i^2} \\mathbf{x}_i \\mathbf{x}_i^T - \\sum_{i=1}^n \\frac{(y_i - \\mu_i) \\mu_i''(\\eta_i)}{\\sigma_i^2} \\mathbf{x}_i \\mathbf{x}_i^T \\\\\n",
    "  & & + \\sum_{i=1}^n \\frac{(y_i - \\mu_i) [\\mu_i'(\\eta_i)]^2 (d \\sigma_i^{2} / d\\mu_i)}{\\sigma_i^4} \\mathbf{x}_i \\mathbf{x}_i^T \\\\\n",
    "\t\\mathbf{FIM}_n(\\beta) &=& \\mathbf{E} [- \\nabla^2 L_n(\\beta)] = \\sum_{i=1}^n \\frac{[\\mu_i'(\\eta_i)]^2}{\\sigma_i^2} \\mathbf{x}_i \\mathbf{x}_i^T = \\mathbf{X}^T \\mathbf{W} \\mathbf{X}.\n",
    "\\end{eqnarray*}    \n",
    "\n",
    "* Fisher scoring method\n",
    "$$\n",
    " \t\\beta^{(t+1)} = \\beta^{(t)} + s [\\mathbf{FIM}(\\beta^{(t)})]^{-1} \\nabla L_n(\\beta^{(t)})\n",
    "$$\n",
    "IRWLS with weights $w_i = [\\mu_i(\\eta_i)]^2/\\sigma_i^2$ and some working responses $z_i$.\n",
    "\n",
    "* For **canonical link**, $\\theta = \\eta$, the second term of Hessian vanishes and Hessian coincides with Fisher information matrix. Convex problem ðŸ˜„\n",
    "$$\n",
    "\t\\text{Fisher's scoring == Newton's method}.\n",
    "$$\n",
    " \n",
    "* Non-canonical link, non-convex problem ðŸ˜ž\n",
    "$$\n",
    "\t\\text{Fisher's scoring algorithm} \\ne \\text{Newton's method}.\n",
    "$$\n",
    "Example: Probit regression (binary response with probit link).\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    y_i &\\sim& \\text{Bernoulli}(p_i) \\\\\n",
    "    p_i &=& \\Phi(\\mathbf{x}_i^T \\beta)  \\\\\n",
    "    \\eta_i &=& \\mathbf{x}_i^T \\beta = \\Phi^{-1}(p_i).\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "where $\\Phi(\\cdot)$ is the cdf of a standard normal.\n",
    " \n",
    "* Julia, R and Matlab implement the Fisher scoring method, aka IRWLS, for GLMs.\n",
    "    * [GLM.jl](https://github.com/JuliaStats/GLM.jl) package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear regression - Gauss-Newton method (KL 14.4-14.6)\n",
    "\n",
    "* Now we finally get to the problem Gauss faced in 1800!  \n",
    "Relocate Ceres by fitting 41 observations to a 6-parameter (nonlinear) orbit.\n",
    "\n",
    "* Nonlinear least squares (curve fitting): \n",
    "$$\n",
    "\t\\text{minimize} \\,\\, f(\\beta) = \\frac{1}{2} \\sum_{i=1}^n [y_i - \\mu_i(\\mathbf{x}_i, \\beta)]^2\n",
    "$$\n",
    "For example, $y_i =$ dry weight of onion and $x_i=$ growth time, and we want to fit a 3-parameter growth curve\n",
    "$$\n",
    "\t\\mu(x, \\beta_1,\\beta_2,\\beta_3) = \\frac{\\beta_3}{1 + e^{-\\beta_1 - \\beta_2 x}}.\n",
    "$$\n",
    "\n",
    "<img src=\"https://cdn.xlstat.com/img/tutorials/nlin5.gif\" width=\"300\" align=\"center\"/>\n",
    "\n",
    "* \"Score\" and \"information matrices\"\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\t\\nabla f(\\beta) &=& - \\sum_{i=1}^n [y_i - \\mu_i(\\beta)] \\nabla \\mu_i(\\beta) \\\\\n",
    "\t\\nabla^2 f(\\beta) &=& \\sum_{i=1}^n \\nabla \\mu_i(\\beta) \\nabla \\mu_i(\\beta)^T - \\sum_{i=1}^n [y_i - \\mu_i(\\beta)] \\nabla^2 \\mu_i(\\beta) \\\\\n",
    "\t\\mathbf{FIM}(\\beta) &=& \\sum_{i=1}^n \\nabla \\mu_i(\\beta) \\nabla \\mu_i(\\beta)^T = \\mathbf{J}(\\beta)^T \\mathbf{J}(\\beta),\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "where $\\mathbf{J}(\\beta)^T = [\\nabla \\mu_1(\\beta), \\ldots, \\nabla \\mu_n(\\beta)] \\in \\mathbb{R}^{p \\times n}$.\n",
    "\n",
    "* **Gauss-Newton** (= \"Fisher's scoring algorithm\") uses $\\mathbf{I}(\\beta)$, which is always psd.\n",
    "$$\n",
    "\t\\boxed{ \\beta^{(t+1)} = \\beta^{(t)} + s [\\mathbf{FIM} (\\beta^{(t)})]^{-1} \\nabla L(\\beta^{(t)}) }\n",
    "$$\n",
    "\n",
    "* **Levenberg-Marquardt** method, aka **damped least squares algorithm (DLS)**, adds a ridge term to the approximate Hessian\n",
    "$$\n",
    "\t\\boxed{ \\beta^{(t+1)} = \\beta^{(t)} + s [\\mathbf{FIM} (\\beta^{(t)}) + \\tau \\mathbf{I}_p]^{-1} \\nabla L(\\beta^{(t)}) }\n",
    "$$\n",
    "bridging between Gauss-Newton and steepest descent.\n",
    "\n",
    "* Other approximation to Hessians: nonlinear GLMs.  \n",
    "See KL 14.4 for examples."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,qmd"
  },
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "441.3333435058594px",
    "left": "0px",
    "right": "903.3333129882813px",
    "top": "140.6666717529297px",
    "width": "166px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
